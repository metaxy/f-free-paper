\documentclass[12pt,a4paper,onecolumn,oneside,titlepage]{article}
\usepackage[utf8]{inputenc}
\usepackage[german]{babel}

\usepackage[T1]{fontenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{tikz}

\usepackage{footnote}
\makesavenoteenv{tabular}

%for pseudocode
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{caption}
\usepackage{graphicx}
\usepackage{caption}
\usepackage{subcaption}
\usepackage{graphvizzz} 
\usepackage{url}


\DeclareCaptionFormat{algor}{%
  \hrulefill\par\offinterlineskip\vskip1pt%
    \textbf{#1#2}#3\offinterlineskip\hrulefill}
\DeclareCaptionStyle{algori}{singlelinecheck=off,format=algor,labelsep=space}
\captionsetup[algorithm]{style=algori}
\usepackage{morewrites}
%return on a new line
\let\oldReturn\Return
\renewcommand{\Return}{\State\oldReturn}

\newcommand{\vars}{\texttt}
\newcommand{\func}{\textsc}
\newcommand\cursive[1]{\ensuremath{\mathcal{#1}}}


\newcommand\todo[1]{\textcolor{red}{#1}}
%\renewcommand\todo[1]{}


\author{Paul Walger}
\title{Heuristiken für das Entfernen von verbotenen Teilgraphen}
\makeindex
\begin{document}

\maketitle
\tableofcontents
\newpage

\section{Einleitung}
Man kann einen Graphen als eine bildliche Darstellung von Beziehungen zwischen Objekten vorstellen. Dabei stellt man sie als Kreise (auch Knoten genannt) mit einem Namen dar und die Beziehungen als als Linien die diese Kreise verbinden (auch Kanten genannt). \cite{Nastos06}  Eine genauere Definition ist im Abschnitt \ref{sec:notation} zu finden.

Diese Graphen können eine Vielzahl von Problemen und Szenarien modellieren. Zum Beispiel könnten sie Knoten Städte und die Kanten Verbindungen zwischen diesen sein und somit wird der Graph das Netzwerk von diesen Städten modellieren. Weitere Bespiele sind im dem Abschnitt \ref{sec:examples} zu finden.

In diesem Abschnitt werden wir die Fundamente legen und diese Arbeit motivieren. Im Abschnitt \ref{sec:algos} werden die Ansätze vorstellt um dieses Problem zu lösen. Dann werden wir im Abschnitt \ref{sec:tests} betrachten wie die Tests aussehen und auf welchen Modellen diese Algorithmen auf ihre Tauglichkeit getestet wurden. Im Abschnitt \ref{sec:implementation} wird Details der Umsetzung von diesen Algorithmen eingegangen. Darauf folgend werden im Abschnitt \ref{sec:results} die Resultate vorgestellt und diskutiert, während im Abschnitt \ref{sec:compare} unsere Lösungen mit anderen bisherigen Lösungsansätzen verglichen werden.

\subsection{Motivation}
Viele verschiedene Probleme erfordern, dass man einen Graphen so wenig wie möglich modifiziert, sodass er zu einer bestimmten Klassen von Graphen gehört. 
Hereditary Graph Klassen = forbidden subgraph characterisation.


\subsection{Anwendungsbeispiele}
\label{sec:examples}

\subsubsection{\textsc{Maximum Clique} auf Co-Graphen}
Um das Problem der \textsc{Maximum Clique} auf einem Graphen $G$ zu finden, so ist es offensichtlich, dass wenn der Graph zwei Zusammenhangskomponenten hat, dann können wir 
\textsc{Maximum Clique} auf den beiden Komponeten lösen und das Maximum davon ist, dass Ergebnis für den Graphen $G$. Hiermit können wir das Problem also in kleinere Probleme zerlegen.
Außerdem gilt es, dass das Finden einer Clique in einem Graphen äquivalent zum Finden der stabilen Menge in der Komplementgraphen ist.
Wir können also unser Problem weiter zerlegen indem wir das Komplement von jeder Zusammenhangskomponenten nehmen und es wieder in seine seine Zusammenhangskomponenten zerlegen. Dabei gilt die maximale stabile Menge die Vereinigung aller maximalen stabilen Mengen der Zusammenhangskomponenten ist.

Eine solche Vorgehensweise ist offesichtlich sehr attraktiv um eine solch schweres Problem, wie \textsc{Maximum Clique} es ist, zu lösen. Dieses Vorgehen hat jedoch ein Problem, wenn das Komplement eines Graphen zusammmenhängend ist und keine Zusammenhangskomponenten hat. Wir definieren, dass $G$ einen complement reducible graph, oder kurz Co-Graph, wenn so etwas in dem Graphen nie auftritt.\cite{Nastos06}

Die Co-Graphen-Klasse hat also sehr wünschenswerte Eigenschaften, wie dass man \textsc{Maximum Clique} in linearer Zeit lösen kann. Diese Klasse ist eine sehr gut studierte Klasse, die in vielen  Anwendungen auftritt.

Co-Graphen lassen sich auch durch charaketerisen, dass sie keinen $P_4$ als induzierten Subgraphen enthalten.
\cite{NastosG13}
\subsubsection{Soziale Netzwerke}

$(P_4,C_4)$-freie Graphen modellieren eine soziale Struktur. \cite{NastosG13}

Ähnlich dazu sind $(P_5,C_5)$-freie Graphen die auch soziale Strukturen modellieren und dafür geeignet sind Gemeinschaften zu identifizieren. \cite{Schoch15}

\subsubsection{Protein interaction networks}
$(2K_2, C_4, C_5)$-freie Graphen haben gewisse Vorteile für die Untersuchung von Interaktionsnetzwerken von Proteinen \cite{BrucknerHK15}.

\subsubsection{Bicluster Editing}

\cite{De12} \cite{Madeira04} 

\subsection{Definitionen}
\subsubsection{Notationen und Definitionen}
\label{sec:notation}
Mit Graphen sei im Folgenden stets ein ungerichteter, einfacher Graph gemeint. Wenn nicht anders angegeben ist $G=(V,E)$ ein Graph, $V$ die Menge seiner Knoten und E die Menge seiner Kanten.

$V(G)$ ist die Menge der Konten des Graphen $G$. $E(G)$ ist die Menge der Kanten des Graphen $G$. $N(u)$ ist die Nachbarschaft vom Knoten $u$. $N^{*}(u)$ ist die Nachbarschaft von $u$ mit $u$ inklusive.

Sei $G = (V,E)$ ein Graph und $S \subseteq V$ eine beliebige Knotenmenge von $V$. 
Dann ist $G[S]$ der auf $S$ induzierte Subgraph von $G$ mit $G[S] = (S, E \cap \{\{u,v\} \,|\, u \in S \land w \in S\})$


Sei $H = (V_H,E_H)$ und $G =(V,E)$ zwei Graphen. Ein Subgraph-Isomorphismus von H nach G ist eine Funktion $f : V_H \rightarrow V$ sodass wenn $(u,v) \in E_H $, dann auch $(f(u),f(v)) \in E$. $f$ ist ein induzierter Subgraph-Isomorphismus, wenn es auch gilt, dass wenn $(u,v) \notin E_H$, dann auch $(f(u),f(v)) \notin E$.

Ein Graph $G$ ist \textit{F}-frei, wenn es nicht \textit{F} als induzierten Subgraphen enthält.
Für eine Menge \cursive{F} von Graphen, heißt $G$ \cursive{F}-frei, wenn $G$ für jeden \textit{F} $\in \cursive{F}$ \textit{F}-frei ist.
Siehe \cite{Cai96} für eine Defintion von FPT und Kernel.

\subsubsection{Problemstellung}
Um Heuristiken für das Entfernen von verbotenen Teilgraphen entwickeln zu können, ist zuerst ein Problem zu definieren. Es ist unter dem Namen \textsc{F-Free Edge Editing}\footnote{oder H-Free (Edge) Editing} bekannt.
\begin{quote}
  \textsc{\cursive{F}-Free Edge Editing}\newline
  \textbf{Eingabe:} Graph $G$, natürliche Zahl $k$\newline
  \textbf{Frage:} Können wir von $G$ höchstens $k$ Kanten entfernen, so dass $G$ keinen induzierten Teilgraphen aus \cursive{F} enthält?\newline
  \textbf{Parameter:} $k$
\end{quote}
\textsc{\cursive{F}-Free Edge Editing} ist NP-Schwer für die meisten \cursive{F}. Man es exakt mit FPT lösen\cite{Cai96}, für die meisten Instanzen von \cursive{F} gibt es keine Polynomiale Kernel.


Die hier vorgestellten Heuristiken.
\begin{quote}
  \textsc{\cursive{F}-Free Edge Editing}\newline
  \textbf{Eingabe:} Graph $G$, natürliche Zahl $k$, Menge von Graphen \cursive{F}\newline
  \textbf{Frage:} Können wir von $G$ höchstens $k$ Kanten entfernen, so dass $G$ keinen induzierten Teilgraphen aus \cursive{F} enthält?\newline
  \textbf{Parameter:} $k$
\end{quote}


\subsection{Ähnliche Arbeiten}
Implicit Hitting Set hilft hier leider nicht viel.\cite{Moreno13} 

Approximation von H-Free Editing für montone graphen eigenschaften: $o(n^2)$ ist effizient, aber $O(n^{2-\epsilon})$ ist NP-Hard.\cite{Alon09}




\section{Algorithmen}
\label{sec:algos}

In diesem Abschnitt werden die verschiedenen Ansätze an die das Problem beschrieben.
Die im nachfolgenden beschriebenen Algorithmen basieren alle auf dem folgenden Prinzip: Suche einen validen Graphen, welcher die verbotenen Subgraphen nicht enthält. Wiederhole dies \vars{iterations}-mal und dann geben die Differenz zwischen  besten validen Graphen und dem Eingabegraphen aus.

Dieses Prinzip ist im Algoritmus \ref{algo:general} zu sehen. Dabei steht \func{SolveAlgo} für einen der Algorithmen, die wir in den folgenden Abschnitten betrachten werden.
\begin{algorithm}
  \captionof{algorithm}{Genereller Aufbau}\label{algo:general}
\begin{algorithmic}[1]
\Function{Solve}{\vars{graph}, \vars{forbidden}, \vars{iterations}}

\State{\vars{best} $\gets$ $(\emptyset,\emptyset)$}

\For{\vars{i} = 1 to \vars{iterations}}
	\State{\vars{valid} $\gets$ \func{solveAlgo}(\vars{graph}, \vars{forbidden})}
	\If{\#(\func{diff}(\vars{best}, \vars{graph})) < \#(\func{diff}(\vars{valid}, \vars{graph}))}
		\State{\vars{best} $\gets$ \vars{valid}}
	\EndIf  
\EndFor

\State{print \func{diff}(\vars{graph}, \vars{best})}
\EndFunction
\end{algorithmic}
\end{algorithm}

Da alle Ansätze diesen Schritte enthalten und sich nur in dem unterschieden, wie der valide Graph gefunden wird, wird folgend nur dieser Aspekt betrachtet.

Die entwickelten Ansätze sind in 3 große Gruppen zu unterteilen.
Der Top-Bottom-Ansatz nimmt den Graphen und ändert ihn solange, bis ein gültiger Graph entsteht. Der Bottom-Top-Ansatz fängt mit einem leeren oder vollen Graphen an, und ändert solange Konten, bis man möglichst nahe an dem Eingabegraphen ist.
Der Grow-Reduce-Ansatz kombiniert diese beiden Ansätze, indem es unterschiedliche Stadien gibt… 

\subsection{Top-Bottom}
Der Top-Bottom-Ansatz nimmt den Graphen und ändert ihn solange, bis ein gültiger Graph entsteht.

\subsubsection{RandomChange}
Das ist der einfachste Algorithmus. Solange der Graph verbotene Subgraphen hat, dann versuche eine Kante in dem Graphen zu ändern. 
\begin{algorithm}
  \captionof{algorithm}{RandomChange}\label{algo:RandomChange}
\begin{algorithmic}[1]
\Function{RandomChangeSolve}{\vars{graph}, \vars{forbidden}}
\For{Graph \vars{f} $\in$ \vars{forbidden} }
	\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph}, \vars{f})}
	\While{forbiddenSubgraph  $\neq \emptyset$}
		\State{change a random edge $\in$ \vars{forbiddenSubgraph}}
		\State{\vars{forbiddenSubgraph} $\gets$	 \func{findFS}(\vars{graph}, \vars{f})}
	\EndWhile
\EndFor
\Return{\vars{graph}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Random}
Es ist wie RandomChange\footnote{Algorithmus \ref{algo:RandomChange}}, aber bereits editierte Kanten werden mit einer geringeren Wahrscheinlichkeit geändert.
Auch hat es für kleine Graphen ein Konvergenzkriterium. Dieses Konvergenzkriterum besteht darin, dass nach für jede Änderung, die Anzahl der verbotenen Subgraphen gezählt wird und die nur dann ausgeführt wird, wenn die Anzahl der verbotenen Subgraphen dadurch weniger wird.
Der allgemeine Vorgehensweise wird im Algorithmus \ref{algo:random} beschrieben.
Der große Unterschied zu zum RandomChange sehen wir ab Zeile  \ref{algo:random:select}. Dort wählen wird die Kante ausgewählt welche geändert werden soll, aber eine bereits geänderte Kante bekommt eine Wahrscheinlichkeit zugewiesen die 4-mal kleiner ist(siehe Zeile \ref{algo:random:prob4}).

\begin{algorithm}
  \captionof{algorithm}{Random}\label{algo:random}
\begin{algorithmic}[1]
\Function{StateRandom2Solve}{\vars{graph}, \vars{forbidden}}
\For{Graph \vars{f} $\in$ \vars{forbidden} }
	\State{f\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph}, \vars{f})}
	\While{\vars{forbiddenSubgraph} != $\emptyset$}
	    \State{\vars{foundEdge} $\gets \emptyset$}
		\While{true\label{algo:random:select}}
			\State{\vars{e} $\gets$ random edge from \vars{forbiddenSubgraph}}
			\State{\vars{prob} $\gets$ 1 / \#(E(f))}
			\If{e is already visited}
				\State{\vars{prob} $\gets$ \vars{prob} / 4}\label{algo:random:prob4}
		    \EndIf
		    \If{random number from [0,1] > \vars{prob}}
		    	\State{\vars{foundEdge} $\gets$ \vars{e}}
		    	\State{break}
		    \EndIf
		    \State{flip \vars{e} in \vars{graph}}
		\EndWhile
		\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph}, \vars{f})}
	\EndWhile
\EndFor
\Return{\vars{graph}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsection{Bottom-Top}
Die Bottom-Top-Ansätze zeichnet sich dadurch aus, dass wir mit einem Graphen beginnen, der die selben Knoten wie der Eingabegraph hat, aber keine Kanten.
Dieser Graph ist somit valide, weil er keine verbotenen Subgraphen enthält.
Dies ist ein Vorteil gegenüber den Top-Bottom-Ansätzen, da es möglich ist immer einen validen Graphen zu haben und somit jederzeit terminieren.
 
\subsubsection{Extend}
Das ist der einfachste Algorithmus aus der Klasse der Bottom-Top-Ansätze.
Zu sehen die Vorgehensweise in Algorithmus \ref{algo:extend}.
Er fängt mit einem Graphen an, der die selben Knoten wie der Eingabegraph hat, aber keine Kanten (Zeile \ref{algo:extend:start}). Dann wird versucht jede Kante einzufügen, die auch im originalen Graphen \vars{input} vorhanden war (Zeile \ref{algo:extend:each}). Wenn es einen invaliden Graphen erzeugt, also dass es nun einen verbotenen Teilgraphen im \vars{graph} gibt, dann wird die Änderung rückgängig gemacht (Zeile \ref{algo:extend:change}).
Wenn nun keine Änderung in einem Durchlauf gemacht wurden, dann bricht der Algorithmus ab (Zeile \ref{algo:extend:break}) und gibt den erzeugen Graphen zurück. 

Ein beispielsweiser Ablauf für den Extend-Algorithmus, wo $P_3$ der verbotene Teilgraph ist ist in der Abbildung \ref{fig:algo:extend} zu sehen. Dabei wird der Graph \vars{graph} dargestellt und eine gestrichelte Kante gibt an, wenn die Kante in dem Graphen \vars{input} vorhanden ist, aber nicht in dem Graphen \vars{input}. Wenn die Kante rot ist, dann wurde versucht die Kante einzufügen, aber es hat eine $P_3$ erzeugt, wenn die Kante grün ist, dann wurde die Kante eingefügt, ohne dass ein $P_3$ erzeugt wurde.

Es ist zu sehen, dass dieser Algorithmus keine Kanten hinzufügt, die nicht in dem Eingabe-Graphen nicht vorhanden waren.

\begin{algorithm}
  \captionof{algorithm}{Extend}\label{algo:extend}
\begin{algorithmic}[1]
\Function{ExtendSolve}{\vars{input}, \vars{forbidden}}
	\State{\vars{graph} = $(V(\vars{input}),\emptyset)$}\label{algo:extend:start}
	\While{true}
		\For{each Edge \vars{e} $\in$ \func{Difference}(\vars{graph},\vars{input}) }\label{algo:extend:each}
			\State{try to flip \vars{e}, revert if it produces an invalid graph}\label{algo:extend:change}
		\EndFor
		\State{break if there was no change}\label{algo:extend:break}
	\EndWhile
\Return{\vars{graph}}
\EndFunction
\end{algorithmic}
\end{algorithm}

  
\begin{figure}
  \centering
  \begin{tabular}[c]{ccc}
    \begin{subfigure}[b]{0.32\textwidth}
      \digraph [width=\linewidth]{dot_extend_1}
      {
       a->b[style=dashed,dir=none];
       a->c[style=dashed,dir=none];
       d->b[style=dashed,dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Startgraph}
      \label{fig:algo:extend:1}
   \end{subfigure}&
   \begin{subfigure}[b]{0.32\textwidth}
     \digraph [width=\linewidth]{dot_extend_2}
      {
       a->b[style=dashed,dir=none];
       a->c[style=dashed,dir=none];
       d->b[color=green,dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Kante (d,b) wird erfolgreich hinzugefügt}
      \label{fig:algo:extend:2}
    \end{subfigure}&
    \begin{subfigure}[b]{0.32\textwidth}
      \digraph [width=\linewidth]{dot_extend_3}
      {
       a->b[style=dashed,dir=none];
       a->c[color=green,dir=none];
       d->b[dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Kante (a,c) erfolgreich wird hinzugefügt}
      \label{fig:algo:extend:3}
    \end{subfigure}
  \end{tabular}
  
    \begin{tabular}[c]{ccc}
    \begin{subfigure}[b]{0.32\textwidth}
      \digraph [width=\linewidth]{dot_extend_4}
      {
       a->b[color=red,dir=none];
       a->c[dir=none];
       d->b[dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Kante (a,b) kann nicht hinzugefügt werden}
      \label{fig:algo:extend:4}
   \end{subfigure}&
   \begin{subfigure}[b]{0.32\textwidth}
     \digraph [width=\linewidth]{dot_extend_5}
      {
       a->b[style=dashed,dir=none];
       a->c[dir=none];
       d->b[dir=none];
       b->c[color=red,dir=none];
      }
      \caption{Kante (b,c) kann nicht hinzugefügt werden}
      \label{fig:algo:extend:5}
    \end{subfigure}&
    \begin{subfigure}[b]{0.32\textwidth}
      \digraph [width=\linewidth]{dot_extend_6}
      {
       a->b[style=dashed,dir=none];
       a->c[dir=none];
       d->b[dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Resultierender Graph}
      \label{fig:algo:extend:6}
    \end{subfigure}
  \end{tabular}
  \caption{Beispielweiser Ablauf des Extends}\label{fig:algo:extend}
\end{figure}

\subsection{GRASP}
\subsubsection{Grow-Reduce}
Der Grow-Reduce-Ansatz ist ein Art von einer greedy randomized adaptive search procedure(GRASP).\todo{GRASPH beschreiben Siehe \cite{Bastos2014}}
Der Grow-Reduce-Ansatz sieht wie folgt aus: Begonnen wird mit einem Graphen, der die selben Knoten wie der Eingabegraph hat, aber keine kanten. Dann wird in jeder Iteration ein Knoten und seine Umgebung hinzugefügt und durch lokale Suche werden alle neu entstandenen verbotenen Subgraphen wieder entfernt.
Die ist im Algorithmus \ref{algo:growReduce} zu sehen. 

\begin{algorithm}
  \captionof{algorithm}{GrowReduce}\label{algo:growReduce}
\begin{algorithmic}[1]
\Function{GrowReduceSolve}{\vars{input}, \vars{forbidden}}
	\State{\vars{graph} $\gets$ $(V(\vars{input}),\emptyset)$}
	\State{\vars{nodes} $\gets$ \func{randomOrder}(V(\vars{input}))}
	\For{\vars{node} $\in$ \vars{nodes}}
		
		\For{\vars{neighbor} $\in$ N(\vars{node})}\Comment{Grow Phase}
			\State{Add Edge (\vars{node}, \vars{neighbor}) to \vars{graph}}
		\EndFor
		\For{\vars{f} $\in$ \vars{forbidden}}\Comment{Reduce Phase}
			\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph},\vars{f})}
			\While{\vars{forbiddenSubgraph} != $\emptyset$}
				\State{\vars{edge} $\gets$ random Edge from \vars{forbiddenSubgraph}}
				\State{\vars{count} $\gets$ \#(\func{findAllFS}(\vars{graph},\vars{f}))}
				\State{flip \vars{edge} in \vars{graph}}
				\State{countAfter $\gets$ \#(\func{findAllFS}(\vars{graph},\vars{f}))}
				\If{\vars{countAfter} $\geq$ \vars{count}}
					\State{flip \vars{edge} in \vars{graph}}
				\EndIf
				\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph}, \vars{f})}
			\EndWhile
		\EndFor
		
	\EndFor
\Return{\vars{graph}}
\EndFunction
\end{algorithmic}
\end{algorithm}

\subsubsection{Explored-Grow-Reduce}
Der Explored-Grow-Reduce-Ansatz ist dem Grow-Reduce-Ansatz ähnlich, bis auf das, es in der Grow-Phase nur die Kanten zu Knoten hinzufügt, die bereits erforscht sind.

Dieser Unterschied wird in der Abbildung \ref{fig:algo_explored} verdeutlich, wo nur die Grow Schritte visualiert wurden, ohne die Reduce-Phase, um es zu vereinfachen.In Abbildung \ref{fig:algo_explored_1} ist der Anfangstatus zu sehen. Die gestrichelten Kanten, sind Kanten die Graphen vorhanden sind, aber noch nicht hinzugefügt worden sind und es wird der Knoten $a$ hinzugefügt, weil aber keine anderen Knoten bisher hinzugefügt worden sind, wird  werden keine Kanten hinzugefügt.
In Abbildung \ref{fig:algo_explored_2} wird der Knoten $b$ hinzugefügt und weil $a$ auch schon hinzugefügt wurde, wird auch die Kante $(a,b)$ hinzugefügt. Aber weder $(a,c)$ noch $(a,b)$ werden hingefügt, weil $c$ noch nicht erforscht wurde.
In Abbildung \ref{fig:algo_explored_3} wird der Knoten $c$ hinzugefügt und somit auch die Kanten $(a,b)$ und $(a,c)$.
	
	
\begin{figure}
  \centering
  \begin{tabular}[c]{ccc}
    \begin{subfigure}[b]{0.32\textwidth}
      \digraph [width=\linewidth]{dot_explored_1}
      {
       a[color=red];
       b[style=dashed];
       c[style=dashed];
       d[style=dashed];
       a->b[style=dashed,dir=none];
       a->c[style=dashed,dir=none];
       d->b[style=dashed,dir=none];
       b->c[style=dashed,dir=none];
      }
      \caption{Knoten a wird hinzugefügt}
      \label{fig:algo_explored_1}
   \end{subfigure}&
	 \begin{subfigure}[b]{0.32\textwidth}
	   \digraph [width=\linewidth]{dot_explored_2}
	    {
	     a[];
	     b[color=red];
	     c[style=dashed];
	     d[style=dashed];
	     a->b[dir=none];
	     a->c[style=dashed,dir=none];
	     d->b[style=dashed,dir=none];
	     b->c[style=dashed,dir=none];
	    }
	    \caption{Knoten b wird hinzugefügt}
	    \label{fig:algo_explored_2}
	  \end{subfigure}&
    \begin{subfigure}[b]{0.32\textwidth}
	    \digraph [width=\linewidth]{dot_explored_3}
	    {
	     a[];
	     b[];
	     c[color=red];
	     d[style=dashed];
	     a->b[dir=none];
	     a->c[dir=none];
	     d->b[style=dashed,dir=none];
	     b->c[dir=none];
	    }
	    \caption{Knoten c wird hinzugefügt}
	    \label{fig:algo_explored_3}
    \end{subfigure}
  \end{tabular}
  \caption{Beispielweise Grow-Phase}\label{fig:algo_explored}
\end{figure}

\begin{algorithm}
  \captionof{algorithm}{ExploredGrowReduce}\label{algo:ExploredGrowReduce}
\begin{algorithmic}[1]
\Function{ExploredGrowReduceSolve}{\vars{input}, \vars{forbidden}}
	\State{\vars{graph} $\gets$ $(V(\vars{input}),\emptyset)$}
	\State{\vars{nodes} $\gets$ \func{order}(V(\vars{input}))}
	\State{\vars{explored} $\gets \emptyset$}
	\For{\vars{node} $\in$ \vars{nodes}}
		
		\For{\vars{neighbor} $\in$ N(\vars{node})}\Comment{Grow Phase}
			\If{\vars{neighbor} $\in$ \vars{explored}}
				\State{Add Edge (\vars{node}, \vars{neighbor}) to \vars{graph}}
			\EndIf
		\EndFor
		\State{\vars{explored} $\gets$ \vars{explored} $\cup$ $\{$\vars{node}$\}$}
		\For{\vars{f} $\in$ \vars{forbidden}}\Comment{Reduce Phase}
			\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph},\vars{f})}
			\While{\vars{forbiddenSubgraph} != $\emptyset$}
				\State{\vars{edge} $\gets$ random Edge from \vars{forbiddenSubgraph}}
				\State{\vars{count} $\gets$ \#(\func{findAllFS}(\vars{graph},\vars{f}))}
				\State{flip \vars{edge} in \vars{graph}}
				\State{countAfter $\gets$ \#(\func{findAllFS}(\vars{graph},\vars{f}))}
				\If{\vars{countAfter} $\geq$ \vars{count}}
					\State{flip \vars{edge} in \vars{graph}}
				\EndIf
				\State{\vars{forbiddenSubgraph} $\gets$ \func{findFS}(\vars{graph}, \vars{f})}
			\EndWhile
		\EndFor
		
	\EndFor
\Return{\vars{graph}}
\EndFunction
\end{algorithmic}
\end{algorithm}
\subsection{Lineare Programmierung}
\subsubsection{Lineare Optimierung}
Bei der linearen Optimierung wird eine lineare Zielfunktion minimiert bzw. maximiert, wobei sie durch lineare Gleichungen und Ungleichungen beschränkt ist.
\subsubsection{Das Model des Graphen}
Wir nutzen binäre Variablen $e_{uv}$, wobei $u,v \in V$ sind und $u < v$ gilt.
Dabei ist $e_{uv} = 1$ genau dann wenn, die kante ${u,v}$ ein Teil des Lösungsgraphen ist.

Wir minimieren \[\sum_{u,v \in V} 
\begin{cases} 
      e_{u,v} & \{u,v\} \in E \\
      -e_{u,v} & \{u,v\} \notin E
   \end{cases}\]
Dies ist die Zielfunktion \vars{objective} im Algorithmus \ref{algo:blp}.

Da alle möglichen Bedingungen hinzuzufügen, welche bei alle verbotenen Subgraphen ausschließen würden, viel zum umfangreich wäre, werden die Bedingungen iterative dort hinzugefügt, wo es einen verbotenen Teilgraphen gibt (siehe Zeile \ref{algo:blp:add}). Dann wird der Problem gelöst(siehe Zeile \ref{algo:blp:solve}) und und die Änderungen auf den Graphen übertragen(siehe Zeile \ref{algo:blp:apply}) . Dann wird wieder nach alle verboteten Subgraphen gesucht(siehe Zeile \ref{algo:blp:findFS}). Dies wird solange wiederholt bis es keine mehr gibt. Nun ist die minimale Anzahl von Änderungen gefunden. 
Dieses Vorgehen ist im Algorithmus \ref{algo:blp} zu sehen.
\begin{algorithm}
  \captionof{algorithm}{F-Free BLP}\label{algo:blp}
\begin{algorithmic}[1]
\Function{solveBLP}{\vars{graph}, \vars{forbidden}}
\State{\vars{constraints} $\gets$ $\emptyset$}
\For{graph \vars{f} $\in$ \vars{forbidden}}
	\While{\func{findFS}(graph, f) != $\emptyset$}\label{algo:blp:findFS}
	  
		\For{each graph M $\in$ \func{findeFS}(\vars{graph}, \vars{f}) } \label{algo:blp:add}
			\State{contstraint $\gets$ 0}
			\For{each $\{u,v\}$ $\in$ E(M)} \Comment{Add all Constraints}
				\If{$\{u,v\}$ $\in$ E(graph)} 
					\State{contstraint += 1 - $e_{uv}$} 
				\Else 
					\State{contstraint += $e_{uv}$} 
				\EndIf
			\EndFor
			\State{\vars{constraints} $\gets$ \vars{constraints} $\cup$ \{ \vars{constraint} \}}
		\EndFor
		\State{\vars{variables} $\gets$ \func{lpSolve}(\vars{constraints}, \vars{objective})}\label{algo:blp:solve}
		\For{$e_{u,v}$ $\in$ \vars{variables}} \Comment{Apply solution to the graph.}\label{algo:blp:apply}
		  \If{$e_{u,v} = 1$}
		    \State{Set edge $(u,v)$ in \vars{graph}}
		  \Else
		    \State{Remove edge $(u,v)$ in \vars{graph}}
		  \EndIf
		\EndFor
	\EndWhile
\EndFor
\Return{graph}
\EndFunction
\end{algorithmic}
\end{algorithm}



\section{Aufbau der Test}
\label{sec:tests}
\subsection{Datensätze}
Folgende Datensätze wurden verwendet. Da verschiedene Mengen von verbotenen Teilgraphen monotonen Grapheneigenschaften zugeordnet werden können und jeder Datensatz von Graphen und jede Methode zufällige Graphen zu erzeugen, charakteristische Eigenschaften hat, ist es notwendig verschiedene Datensätze zu verwenden und verschiedenen Methoden zur Erzeugung von zufälligen Graphen.
Ingesammt wurde 5 verschiedene Methoden zur Erzeugung von zufälligen Graphen verwendet und 3 Datensätze.
Wir brachten zuerst die zufälligen Graphen.


\subsubsection{Barabási–Albert}
Für den Datensatz \vars{barabasi\_albert} wurde das Barabási–Albert Modell verwendet, welches ein zufälliges skalenfreies Netz erzeugt.\cite{Albert02}
Skalenfrei bedeutet hier, dass die Knotengrad einer Potenzverteilung folgt. Es gibt also viel mehr Konten die einen geringeren Grad haben als Knoten mit einem hohen Anzahl von Nachbarn. 

Es wurden 56 Graphen generiert mit Knotenanzahl zwischen 10 und 150, wobei der Parameter $m$, welcher die Anzahl der der Kanten definiert, die zu bereits bestehenden Knoten erstellt werden, zwischen 1 und 8 war.
\subsubsection{Erdős-Rényi}
Für den Datensatz \vars{binomial} wurde das Erdős-Rényi Modell verwendet\cite{Gilbert59} \cite{Batagelj05}, wo jede Kante eine fixe Wahrscheinlichkeit hat zu existieren oder nicht zu existieren.

Es wurden dabei 54 Graphen generiert, mit einer Knotenanzahl zwischen 10 und 100 und den folgenden Wahrscheinlichkeiten: $\frac{1}{10}$, $\frac{2}{10}$, $\frac{5}{20}$, $\frac{4}{10}$, $\frac{5}{10}$, $\frac{8}{10}$.


\subsubsection{Duplication-Divergence}
Für den Datensatz \vars{duplication divergence} wurde das Duplication Divergence Modell verwendet\cite{Ispolatov05}, welches Interaktionsnetzwerke zwischen Proteinen modelliert. Ein Beispiel ist in Abbildung \ref{fig:duplication-divergence} zu sehen.

Dabei gibt es in jeder Iteration bei der Erstellung eines solchen zufälligen Graphen zwei Phase. Die erste ist die Duplikations-Phase, wo ein zufälliger Knoten $u$ genommen und dupliziert wird zu $v$. Dann beginnt die Divergence-Phase, wo zu jedem Nachbarn von $u$ mit gewissen Wahrscheinlichkeit $p$ eine Kante zu $v$ hinzugefügt wird. Falls keine Kanten hinzugefügt wurde, dann wird $v$ wieder gelöscht. Dies wird $n$-mal wiederholt 

Es wurden mit diesem Modell 54 Graphen generiert mit $n$ zwischen 10 und 100. Für die Wahrscheinlichkeiten $p$ wurden folgenden Werte verwendet $\frac{1}{10}$, $\frac{2}{10}$, $\frac{5}{20}$, $\frac{4}{10}$, $\frac{5}{10}$, $\frac{8}{10}$.
\begin{figure}
\digraph
[scale=0.4]{dot_dupdivergence}
{
0->8;
0->1;
0->12;
1->16;
1->2;
1->3;
1->4;
1->5;
1->6;
1->7;
1->17;
1->11;
1->13;
5->8;
5->10;
5->19;
5->12;
7->8;
7->19;
8->18;
8->9;
8->14;
8->15;
14->19;
15->19;
}
\caption{Ein beispielhafter Duplication-Divergence Graph mit $n$ = 20 und $p$ = 0,4}
\label{fig:duplication-divergence}
\end{figure}

\subsubsection{Newman-Watts-Strogatz}
Für den Datensatz \vars{newman\_watts\_strogatz} wurde das Newman-Watts-Strogatz Modell verwendet\cite{Newman99}, welches einen Kleine-Welt-Graphen erzeugt mit kurzen durchschnittlichen Pfaden und einem hohen Clusterkoeffizienten.

Dabei wird zuerst ein Ring von $n$ Knoten erstellt. Dann wird jeder Knoten mit $k$ von seinen nächsten Nachbarn verbunden (oder mit $k-1$, wenn $k$ ungerade ist).
Dann werden Abkürzungen erzeugt indem, man für jede Kante $(u,v)$ in dem zugrundeliegenden $n$-Ring mit den $k$-nächsten Nachbarn: Füge mit der der Wahrscheinlichkeit $p$ eine neue Kante $(u,w)$ ein, wobei $w$ ein zufälliger existierender Knoten ist.

Es wurden mit diesem Model 144 Graphen generiert mit einer Knotenanzahl($n$) zwischen 10 und 100, $m$ zwischen 2 und 8 und der Wahrscheinlichkeit $p$ zwischen 0,2 und 0,8.

\subsubsection{Powerlaw-Baum}
Für den Datensatz \vars{powerlaw}, wurde ein Modell verwendet, dass einen Baum erzeugt, deren Knotengrad einer Potenzverteilung folgt. Ein Beispiel ist in Abbildung \ref{fig:powerlaw-tree} zu sehen.
Es wurden mit diesem Model 30 Graphen generiert mit einer Knotenanzahl zwischen 10 und 160.
\begin{figure}
 \digraph
[scale=0.4]{dot_powerlaw}
{
 0->1;
1->2;
2->3;
3->4;
4->5;
4->7;
5->8;
5->9;
5->6;
}
\caption{Ein Powerlaw-Baum mit $n$ = 10}
\label{fig:powerlaw-tree}
\end{figure}

\subsubsection{UCINetworkDataRepository}
Für den Datensatz \vars{UCINetworkDataRepository} wurden 9 reale Graphen verwendet, bereitgestellt von der University of California.

Der Graph \vars{karate} ist ein soziales Netzwerk von Freundschaften zwischen 34 Mitgliedern eines Karate-Clubs in einer US-Universität in 1970 \cite{Zachary77}.

Der Graph \vars{polbooks.paj} ist ein Netzwerk von Bücher über die aktuelle US Politik, die von dem Onlinehänder Amazon.com verkauft wurdem. Kanten repräsentieren häufiges Kaufen von den beiden Büchern von dem selben Käufer \cite{polbooks}.

Der Graph \vars{football} ist ein Netzwerk von amerikanischen Footballspielen im Herbst 2000 \cite{Girvan02}.

Der Graph \vars{power.paj} ist ein Netzwerk, dass die Topologie des "Western States Power Grid" in der Vereinigten Staaten wiederspieglt  \cite{Watts98}.

Der Graph \vars{adjnoun} ist ein Netzwerk von häufigen Adjektiven und Nomen in dem Roman "David Copperfield" von Charles Dickens \cite{Newman06}.

Der Graph \vars{lesmiserables} ist ein Netwerke von Figuren, die in dem  Roman "Les Misérables" von Victor Hugo, zur gleichen Zeit auftreten \cite{Knuth93}. 


Der Graph \vars{celegansneural.paj} welches das neurale Netzwerk von Caenorhabditis elegans \cite{Watts98}. Es ist ein Fadenwurm, welcher gerne als Modellorganismus studiert wird. Jeder erwachsene C. elegans hat genau 302 Nervenzellen.


Der Graph \vars{dolphins} ist ein soziales Netzwerk von 62 Dolphinen die in einer Gemeinschaft in der Nähe von Neuseeland leben \cite{Lusseau03}. 

Der Graph \vars{polblogs} ist ein Netzwerk von Hyperlinks zwischen Webblogs in 2005, die sich mit auf US Politik beschäftigten \cite{Adamic05}.

\subsubsection{bio1}
Anzahl: 147
\todo{Was ist die Quelle für diese Daten???}
\subsubsection{bio2}
Der Datensatz \vars{bio2} sind COG protein similarity data \cite{Rahmann07} \cite{Bocker08}
Es sind 360 Graphen mit einer Knotenanzahl zwischen 3 und 80.



\subsection{Optimale Lösung}
Um die Qualität der Lösung eines heuristischen Ansatzes bewerten zu können, ist es sehr gut die optimale Lösung zu wissen. Es gibt verschiedene Ansatz wie das Problem zu lösen sein, wir haben uns jedoch für die lineare Optimierung entschieden. 

\section{Implementation}
\label{sec:implementation}
\subsection{Repräsentation vom Graphen}
Die Graphen werden in einer Adjazenzmatrix gespeichert.


\subsection{Das Finden von induzierten Subgraphen}
\cite{Ullmann76}
Wie verwenden einen VF Algorithmus für \func{findFS}(\vars{graph},\vars{forbidden}).
Dieser gibt gibt eine Menge von Subgraphen zurück.

\subsubsection{Vergleich VFLib, Boost und eigene Implemtation}
\begin{tabular}{|c|c|c|c|}
\hline 
• & find all p3s & count all p3s & has a p3 \\ 
\hline 
Spezial & 0.73s & 0.04s & 0.00016s \\ 
\hline 
VFLib & 1.73s & 0.87s & 0.01236s \\ 
\hline 
Boost & 3.04s & 1.68 & 0.00102s \\ 
\hline 
\end{tabular} 
\\

Bei VFLib ist der Graph immutable und bei der Suche nach einem  Subgraphen müssen wir jedes Mal den Graphen neu erstellen.


\section{Auswertung}
\label{sec:results}

\section{Vergleich mit anderen Heuristiken}
\label{sec:compare}

\subsection{Cluster-Editing}
\subsubsection{2K-Heuristik}
Die 2K-Heuristik basiert auf einem Kernel für das Cluster-Editing-Problem, welches maximal 2K Knoten liefert \cite{Chen12}. Wenn man dort eine Bedingung für die Reduktionsregel  abschwächt, kommt eine gute Heuristik für das Cluster-Editing-Problem heraus. Dabei wird die Bedingung mit jedem Durchlauf abgeschwächt.
\pagebreak
\begin{center}
  \captionof{algorithm}{2K Heuristik}\label{algo:2k}
\begin{algorithmic}[1]
\Function{solve2K}{\vars{g} :: Gewichteter Graph}
\State{\vars{x} $\gets$ 1,0} 
\While{\vars{g} has a P3}
	\For{each knoten \vars{u} $\in$ \vars{g}}
		\If{$2 \cdot x \cdot costClique(g, u) + x \cdot costCut(g, u) < \#(N(u))$}
			\For{each $\{a,b\}$  mit $a \in N(u)$, $b \in N(u) \land a \neq b$}
				\State{\func{merge}(a,b)}
			\EndFor
		\EndIf
	\EndFor
	\State{$\vars{x} \gets$ $0,99 \cdot \vars{x} - 0,01$}
\EndWhile

\Return{graph}
\EndFunction

\Function{costClique}{graph :: Gewichteter Graph, u :: Kante}
\State{cost $\gets$ 0}
	\For{each $\{a,b\}$  mit $a \in N^{*}(u)$, $b \in N^{*}(u) \land \{a,b\} \notin graph$}
		\State{cost += $|\,w(\{a,b\})\,|$}
	\EndFor

\Return{cost}
\EndFunction
\Function{costCut}{graph :: Gewichteter Graph, u :: Kante}
\State{cost $\gets$ 0}
	\For{each $\{a,b\}$  mit $a \in N^{*}(u)$, $b \notin N^{*}(u) \land \{a,b\} \in graph$}
		\State{cost += $w(\{a,b\})$}
	\EndFor

\Return{cost}
\EndFunction
\end{algorithmic}
\end{center}


\begin{center}
\captionof{table}{Vergleich der durchschnittlichen Lösungsgröße}
\label{tab:size_2k}
\begin{tabular}{|c|c c|c c|}

\hline 
Programm / & \multicolumn{2}{c|}{Aprox2k} & \multicolumn{2}{c|}{ExploredGrowReduce\footnote{Siehe Algorithmus \ref{algo:ExploredGrowReduce} mit 5 Iterationen }} \\ 
Datensatz & \multicolumn{1}{c}{mean}  &  \multicolumn{1}{c|}{std} &  \multicolumn{1}{c}{mean} &  \multicolumn{1}{c|}{std} \\ 
\hline 
bio1 \footnote{Testergebnis: 2016-04-20 17:29:08} & \textbf{43.44}  & 79.81 & 133.59 & 249,62 \\ 
bio2 \footnote{Testergebnis: 2016-04-20 17:31:40} & \textbf{34.11} & 19.79 & 113.81 & 166,01 \\ 
duplication-divergence \footnote{Testergebnis: 2016-04-20 17:36:40} & 155.17 & 217.38 & \textbf{92.30} & 115,22 \\ 
newman-watts-strogatz \footnote{Testergebnis: 2016-04-20 17:36:57} & 165.22 & 149,86 & \textbf{152.34} & 127,51 \\ 
albert-barabasi \footnote{Testergebnis: 2016-04-20 17:38:17} & 324.30 & 316,32 & \textbf{248.84} & 226,87 \\ 
binomial \footnote{Testergebnis: 2016-04-20 18:17:08} & \textbf{493.17} & 545,19 & 554.61 & 670,91 \\ 
 
\hline 
\end{tabular} 
\end{center}


\subsection{Quasi-Threshold Mover}
In \cite{BrandesHSW15} wurde ein neuer schneller und auch für große Graphen geeigneter Algorithmus entwickelt für das Quasi-Threshold Editing Problem. Quasi-Threshold Graphen, auch bekannt als trivial perfekte Graphen lassen sich auch als $(P_4, C_4)$ - freie Graphen charakterisieren. 

In Tabelle \ref{tab:qual_mover} wird die Lösungsqualität von dem Quasi-Thresold-Mover und unserem Algorithmus ExploredGrowReduce verglichen. In der Tabelle \ref{tab:size_mover} wird die durschnittliche Größe der Lösungen verglichen. 
Der Quasi-Threschold-Mover ist unserem Ansatz weit überlegen. 
\begin{center}
\captionof{table}{Vergleich der durchschnittlichen Lösungsqualität}
\label{tab:qual_mover}
\begin{tabular}{|c|c c|c c|}

\hline 
Programm / & \multicolumn{2}{c|}{ExploredGrowReduce\footnote{Siehe Algorithmus \ref{algo:ExploredGrowReduce} mit Standard-Parametern }} & \multicolumn{2}{c|}{Quasi-Threshold-Mover} \\ 
Datensatz & \multicolumn{1}{c}{mean}  &  \multicolumn{1}{c|}{std} &  \multicolumn{1}{c}{mean} &  \multicolumn{1}{c|}{std} \\ 
\hline 
bio1 \footnote{Testergebnis: 2016-04-20 12:46:35 } & 1.61x  & 1.30 & \textbf{1.05x} & 0.14 \\ 

bio2 \footnote{Testergebnis: 2016-04-20 12:53:45} & 1.69x & 1.03 & \textbf{1.05x} & 0.10 \\ 

duplication-divergence \footnote{Testergebnis: 2016-04-20 13:09:36} & 1.42x & 0.33 & \textbf{1.04x} & 0.05 \\ 

newman-watts-strogatz \footnote{Testergebnis: 2016-04-20 13:12:44} & 1.38x & 0.22 & \textbf{1.06x} & 0.05 \\ 
\hline 
\end{tabular} 
\end{center}

\begin{center}
\captionof{table}{Vergleich der durchschnittlichen Lösungsgröße}
\label{tab:size_mover}
\begin{tabular}{|c|c c|c c|}

\hline 
Programm / & \multicolumn{2}{c|}{ExploredGrowReduce} & \multicolumn{2}{c|}{Quasi-Threshold-Mover} \\ 
Datensatz & \multicolumn{1}{c}{mean}  &  \multicolumn{1}{c|}{std} &  \multicolumn{1}{c}{mean} &  \multicolumn{1}{c|}{std} \\ 
\hline 
bio1 & 52.25  & 150.25 & \textbf{20.88} & 46.51 \\ 

bio2 & 23.12 & 19.91 & \textbf{13.89} & 9.64 \\ 

duplication-divergence & 73.87 & 117.35 & \textbf{51.46} & 80.23 \\ 

newman-watts-strogatz & 146.48 & 128.42 & \textbf{103.38} & 87.99 \\ 
\hline 
\end{tabular} 
\end{center}


\section{Zukünftige Forschungsmöglichkeiten}
\subsection{Besser Sortierung von Grow-Reduce}
\subsection{Besser Konvergenzkriterium}
\subsection{Obere Schranken}
\subsection{Obere Schranken}
\section{Zusammenfassung}

\section{Anhang}
\subsection{Kleine Graphen}

\begin{figure}
  \centering
  \begin{tabular}[c]{cccc}
    \begin{subfigure}[b]{0.20\textwidth}
      \digraph
[width=\linewidth]{dot_p3}
{
	a->b->c;
}
      \caption{$P_3$}
      \label{fig:graphs:p3}
    \end{subfigure}&
    \begin{subfigure}[b]{0.20\textwidth}
     \digraph
[width=\linewidth]{dot_p4}
{
  a->b->c->d;
}
      \caption{$P_4$}
      \label{fig:graphs:p4}
    \end{subfigure}&
    \begin{subfigure}[b]{0.20\textwidth}
      \digraph
[width=\linewidth]{dot_c4}
{
  a->b->c->d->a;
}
      \caption{$C_4$}
      \label{fig:graphs:c4}
    \end{subfigure}&
    \begin{subfigure}[b]{0.20\textwidth}
     \digraph
[width=\linewidth]{dot_2k2}
{
  a->b;
  c->d;
}
      \caption{$2K_2$}
      \label{fig:mouse}
    \end{subfigure}
  \end{tabular}
  \caption{Einige Graphen}\label{fig:animals}
\end{figure}

\bibliographystyle{plain}
\bibliographystyle{te}
\bibliography{biblio}

\end{document}
